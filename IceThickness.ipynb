{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IceSat-2 Satellite Polar Ice Thickness\n",
    "## Jeff Liu\n",
    "#### Bayesian modeling of ice thickness given a satellite freeboard measurement with a hierarchical nonlinear multivariate truncated Gaussian model\n",
    "#### Posterior sampled using Metropolis-within-Gibbs style Markov Chain Monte Carlo.\n",
    "\n",
    "See the paper for full details of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm, multivariate_normal, invgamma\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note on Constants\n",
    "\n",
    "I got a (somewhat) arbitrary estimate of average snow depth of 0.15 meters from https://earthobservatory.nasa.gov/images/146758/mapping-snow-on-arctic-sea-ice.\n",
    "I also borrowed average ice thickness of 2 meters from lecture, along with the lower/upper bounds that come up in the `CheckPriorBounds` function.\n",
    "\n",
    "The variances I chose are wide to be less informative, but the bounds are truncated to prevent this from introducing inaccuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "var_rw = 0\n",
    "var_ri = 0\n",
    "var_rs = 0\n",
    "var_H = 0\n",
    "\n",
    "mean_rw = 1020\n",
    "mean_ri = 910\n",
    "mean_rs = 300\n",
    "mean_H = 2 # from lecture\n",
    "mean_S = 0.15 # eyeballed estimate from CryoSat-2 website\n",
    "mu_x = np.array([mean_rw, mean_ri, mean_rs, mean_H, mean_S]) # combined into one mean vector\n",
    "\n",
    "# chosen somewhat arbitrarily\n",
    "alpha_eps = 0\n",
    "beta_eps = 0\n",
    "\n",
    "alpha_s = 0\n",
    "beta_s = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Model\n",
    "Computes the model's prediction of Freeboard given the three densities, snow thickness, and ice thickness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ForwardModel(rw, ri, rs, H, S):\n",
    "    return (rw-ri)/rw * (H - S*(rs/(rw-ri)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood Function\n",
    "\n",
    "Evaluate log of the likelihood of the freeboard measurement `F` given params `x` and some hierarchally modeled additive error `var_eps`:\n",
    "\n",
    "$f(F | x, \\epsilon) \\sim N(0, \\epsilon) $\n",
    "\n",
    "where the value to evaluate the likelihood at is $F - g(x)$ where $g(x)$ is the forward model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogLikelihood(x, F, var_eps):\n",
    "    \"\"\"\n",
    "    ARGS:\n",
    "        x (np.array): A numpy array of length 5 containing the model parameters: rw, ri, rs, H, S\n",
    "        F (float): A scalar containing the observation of freeboard F\n",
    "        var_eps (float): A scalar containing the given error variance\n",
    "        \n",
    "    RETURNS:\n",
    "        (float): A scalar containing log( f(F | x, var_eps) )\n",
    "    \"\"\"\n",
    "    rw, ri, rs, H, S = x\n",
    "    diff = F - forwardModel(rw, ri, rs, H, S)\n",
    "    sigma_eps = sqrt(var_eps)\n",
    "    \n",
    "    return norm.logpdf(diff, 0, sigma_eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bounds checking on prior\n",
    "\n",
    "Since our prior consists of truncated normal distributions, we need to check if the proposed parameters `x` fit this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CheckPriorBounds(x):\n",
    "    rw, ri, rs, H, S = x\n",
    "    return 1010 <= rw <= 1030 and 750 <= ri <= 940 and 100 <= rs <= 400 and 0.1 <= H <= 5 and S >= 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior Density of parameters\n",
    "\n",
    "Evaluates log of the prior density of proposed parameters `x` given some variable snow variance:\n",
    "\n",
    "$f(x|\\sigma^2_S) \\sim N(\\mu_x, cov_x)$\n",
    "\n",
    "where the covariance contains our snow variance, and where we evaluate the density with our proposed `x`.\n",
    "\n",
    "Assume that the covariance matrix is diagonal; i.e. we have an independent prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogPrior(x, var_S):\n",
    "    \"\"\"\n",
    "    ARGS:\n",
    "        x (np.array): A numpy array of length 5 containing the model parameters: rw, ri, rs, H, S\n",
    "        var_S (float): A scalar containing the snow variance\n",
    "        \n",
    "    RETURNS:\n",
    "        (float): A scalar containing log( f(x | var_S) )\n",
    "    \"\"\"\n",
    "    \n",
    "    if not CheckPriorBounds(x):\n",
    "        return -1e10 # big negative value, means zero basically if out of bounds\n",
    "    \n",
    "    rw, ri, rs, H, S = x\n",
    "    \n",
    "    # the first four are global vars; var_S is a variable parameter\n",
    "    cov_x = np.diag([var_rw, var_ri, var_rs, var_H, var_S])\n",
    "    \n",
    "    return multivariate_normal.logpdf(x, mean=mu_x, cov=cov_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Gamma Hyperprior on variances\n",
    "Evaluates the log of the inverse-gamma density on some variance and hyperparameters $\\alpha$ and $\\beta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogInvGamma(var, alpha, beta):\n",
    "    return invgamma.logpdf(var, a=alpha, scale=1/beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior on parameters\n",
    "Evaluates log of the posterior on model parameters `x`:\n",
    "\n",
    "$f(x|F,\\epsilon,\\sigma^2_S) \\propto f(F | x, \\epsilon ) \\cdot f(x|\\sigma^2_S)$\n",
    "\n",
    "which is the likelihood times the prior on `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogPosteriorX(x, F, var_eps, var_S):\n",
    "    \"\"\"\n",
    "    ARGS:\n",
    "        x (np.array): A numpy array of length 5 containing the model parameters: rw, ri, rs, H, S\n",
    "        F (float): A scalar containing the observation of freeboard F\n",
    "        var_eps (float): A scalar containing the given error variance\n",
    "        var_S (float): A scalar containing the snow variance\n",
    "        \n",
    "    RETURNS:\n",
    "        (float): A scalar containing log( f(x | F, var_eps, var_S) )\n",
    "    \"\"\"\n",
    "    return LogLikelihood(x, F, var_eps) + LogPrior(x, var_S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior on error\n",
    "Evaluates log of the posterior on the error variance on "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
